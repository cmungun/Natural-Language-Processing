{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. STEMMING OF WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing the words to their root.\n",
    "stemming are used to prepare text,words. Also known as word normalization.\n",
    "Stemming mostly used for tagging systems, web search results and informational \n",
    "retrieval. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happi\n",
      "lazi\n"
     ]
    }
   ],
   "source": [
    "# STEMMING OF WORDS\n",
    "#nltk: python nltk package--> natural language tool kit-->for NLP tasks\n",
    "#import nltk package\n",
    "#nltk package--->English and non-english stemmers\n",
    "import nltk\n",
    "\n",
    "#different stemmers availavle in different languages\n",
    "#PorterStammer for English language\n",
    "#nltk.stem-->package---->performs stemming\n",
    "#PorterStammer--->class of nltk.stem\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#create an object of PorterStemmer\n",
    "stemmerporter = PorterStemmer()\n",
    "#Word to be stemmed\n",
    "#object.class\n",
    "print(stemmerporter.stem('happiness'))\n",
    "print(stemmerporter.stem('laziness'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drink\n",
      "have\n"
     ]
    }
   ],
   "source": [
    "#words ending with 'ing'\n",
    "##Word to be stemmed\n",
    "#object.class\n",
    "print(stemmerporter.stem('drinking'))\n",
    "print(stemmerporter.stem('having'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sing\n",
      "laugh\n"
     ]
    }
   ],
   "source": [
    "#words ending with 'ing'\n",
    "stemmerporter = PorterStemmer()\n",
    "print(stemmerporter.stem('singing'))\n",
    "print(stemmerporter.stem('laughing'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laugh\n",
      "terribl\n"
     ]
    }
   ],
   "source": [
    "print(stemmerporter.stem('laugh'))\n",
    "#PorterStemmer algorithm does not follow linguistics\n",
    "print(stemmerporter.stem('terribly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am quick fox jump over a lazi dog\n"
     ]
    }
   ],
   "source": [
    "# STEMMING PARAGRAPH\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "example = \"Am quick fox jumps over a lazy dog\"\n",
    "#stemming whole sentence\n",
    "#1. splitted into words(token)\n",
    "#2.porterstemming applied over words\n",
    "example = [stemmer.stem(token) for token in example.split(\" \")]\n",
    "#join()--->join all stem words into sentence\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I -------> I\n",
      "have -------> have\n",
      "been -------> been\n",
      "a -------> a\n",
      "devotee -------> devote\n",
      "of -------> of\n",
      "the -------> the\n",
      "elegant -------> eleg\n",
      "styling -------> style\n",
      "and -------> and\n",
      "functionality -------> function\n",
      "of -------> of\n",
      "all -------> all\n",
      "things -------> thing\n",
      "Apple -------> appl\n",
      ". -------> .\n"
     ]
    }
   ],
   "source": [
    "# Import library word_tokenizer from nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.stem performs stemming using different classes\n",
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()\n",
    "#sentence from above text\n",
    "sentence =  \"I have been a devotee of the elegant styling and functionality of all things Apple .\"\n",
    "words = word_tokenize(sentence) \n",
    "for w in words: \n",
    "    print(w, \"------->\", pst.stem(w)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mang'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SnowballStemmer used for non-English Stemmers\n",
    "##nltk.stem-->package---->performs stemming\n",
    "#SnowballStemmer--->class of nltk.stem\n",
    "#Danish, Dutch, English, French, German, Hungarian, Italian, Norwegian,Porter\n",
    "#Portuguese, Romanian, Russian, Spanish,Swedish\n",
    "from nltk.stem import SnowballStemmer\n",
    "#SnowballStemmer.languages--->includes languages\n",
    "SnowballStemmer.languages\n",
    "#for french language, created object->frenchstemmer\n",
    "frenchstemmer =  SnowballStemmer('french')\n",
    "frenchstemmer .stem('manges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I -------> i\n",
      "have -------> have\n",
      "been -------> been\n",
      "a -------> a\n",
      "devotee -------> devote\n",
      "of -------> of\n",
      "the -------> the\n",
      "elegant -------> eleg\n",
      "styling -------> style\n",
      "and -------> and\n",
      "functionality -------> function\n",
      "of -------> of\n",
      "all -------> all\n",
      "things -------> thing\n",
      ". -------> .\n"
     ]
    }
   ],
   "source": [
    "#SnowballStemmer used for non-English Stemmers\n",
    "##nltk.stem-->package---->performs stemming\n",
    "#SnowballStemmer--->class of nltk.stem\n",
    "#Danish, Dutch, English, French, German, Hungarian, Italian, Norwegian,Porter\n",
    "#Portuguese, Romanian, Russian, Spanish,Swedish\n",
    "from nltk.stem import SnowballStemmer\n",
    "#SnowballStemmer.languages--->includes languages\n",
    "SnowballStemmer.languages\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "sentence1 =  \"I have been a devotee of the elegant styling and functionality of all things .\"\n",
    "words1 = word_tokenize(sentence1) \n",
    "for w in words1: \n",
    "    print(w, \"------->\",stemmer.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'morg'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SnowballStemmer used for non-English Stemmers\n",
    "##nltk.stem-->package---->performs stemming\n",
    "#SnowballStemmer--->class of nltk.stem\n",
    "#Danish, Dutch, English, French, German, Hungarian, Italian, Norwegian,Porter\n",
    "#Portuguese, Romanian, Russian, Spanish,Swedish\n",
    "from nltk.stem import SnowballStemmer\n",
    "#SnowballStemmer.languages--->includes languages\n",
    "SnowballStemmer.languages\n",
    "\n",
    "#for german language\n",
    "frenchstemmer =  SnowballStemmer('german')  # GERMAN\n",
    "frenchstemmer .stem('morgen') #morning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 : Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula\n"
     ]
    }
   ],
   "source": [
    "# LEMMATIZER\n",
    "# grouping together the inflected forms of a word\n",
    "#WordNetLemmatizer is a class from nltk.stem package\n",
    "#lookup into dictionary\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#object created--->lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#lemma for the word# LEMMATIZER\n",
    "print(lemmatizer.lemmatize(\"formulae\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stimulae\n",
      "good\n",
      "Am\n"
     ]
    }
   ],
   "source": [
    "# LEMMATIZER\n",
    "print(lemmatizer.lemmatize(\"stimulae\"))\n",
    "\n",
    "#pos----->denote---->a: adjective\n",
    "print(lemmatizer.lemmatize(\"better\",pos = 'a'))\n",
    "\n",
    "print(lemmatizer.lemmatize(\"Am\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n",
      "have\n",
      "cactus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pos----> denote v---->verb\n",
    "print(lemmatizer.lemmatize(\"am\",pos = 'v'))\n",
    "\n",
    "#pos----->denote v------>verb\n",
    "print(lemmatizer.lemmatize(\"had\",pos = 'v'))\n",
    "#for word cacti\n",
    "print(lemmatizer.lemmatize(\"cacti\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large\n",
      "advance\n",
      "answer\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "#object created--->lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#lemma for the word\n",
    "#for word cacti\n",
    "#pos----->denote---->a: adjective\n",
    "print(lemmatizer.lemmatize(\"larger\",pos = 'a'))\n",
    "print(lemmatizer.lemmatize(\"advanced\",pos = 'v'))\n",
    "print(lemmatizer.lemmatize(\"answer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jump'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class------> RegexpStemmer from nltk.stem package\n",
    "#uses regular expressions to identify morphological affixes\n",
    "#substrings that match the regular exp that will be removed\n",
    "from nltk.stem import RegexpStemmer\n",
    "#substring----> 'ing'\n",
    "#object-->stemmerregexp\n",
    "stemmerregexp = RegexpStemmer('ing')\n",
    "#for word laughing \n",
    "stemmerregexp.stem('Jumping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "#substring----> 'ing'\n",
    "#object-->stemmerregexp\n",
    "stemmerregexp = RegexpStemmer('ing')\n",
    "#for word laughing\n",
    "stemmerregexp.stem('Singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'make'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "#substring----> 'ing'\n",
    "#object-->stemmerregexp\n",
    "stemmerregexp = RegexpStemmer('r')\n",
    "#for word laughing पक्षाच\n",
    "stemmerregexp.stem('maker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Marathi Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'लढवा'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class------> RegexpStemmer from nltk.stem package\n",
    "#uses regular expressions to identify morphological affixes\n",
    "#substrings that match the regular exp that will be removed\n",
    "from nltk.stem import RegexpStemmer\n",
    "#substring----> 'ing'\n",
    "#object-->stemmerregexp\n",
    "stemmerregexp = RegexpStemmer('यचा')\n",
    "#for word laughing पक्षाच\n",
    "stemmerregexp.stem('लढवायचा')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'पक्ष'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerregexp = RegexpStemmer('ाचा')\n",
    "#for word laughing पक्षाच\n",
    "stemmerregexp.stem('पक्षाचा')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'सहभाग'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerregexp = RegexpStemmer('ाने')\n",
    "#for word laughing पक्षाच\n",
    "stemmerregexp.stem('सहभागाने')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अध्यक्ष'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerregexp = RegexpStemmer('तेखाली')\n",
    "stemmerregexp.stem('अध्यक्षतेखाली')#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LancasterStemmer---->iterative algorithm\n",
    "#English stemmer\n",
    "#it tries to find applicable rule by last character of the word.\n",
    "#each rule specifies either a deletion or replacement of an ending\n",
    "#produces an even shorter stem than porter\n",
    "#class------>LancasterStemmer from nltk.stem package\n",
    "from nltk.stem import LancasterStemmer\n",
    "#object------->stemmerLan \n",
    "stemmerLan = LancasterStemmer()\n",
    "#for word happiness\n",
    "stemmerLan.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lazy'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerLan = LancasterStemmer()\n",
    "#for word laziness\n",
    "stemmerLan.stem('laziness')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
